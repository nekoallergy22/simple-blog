---
title: "ニューラルネットワークの基本構造"
date: "2025-6-29"
tags: ["ニューラルネットワーク", "パーセプトロン", "多層パーセプトロン", "隠れ層", "深層学習"]
section: "ai"
slug: "17-neural-network-basic-structure"
number: 17
category: "強化学習・評価編"
---

コンピュータが人間の脳のような学習能力を持つには、どんな仕組みが必要でしょうか？この記事では、人工知能の核心技術である **ニューラルネットワーク** の基本構造について、人間の脳の仕組みと比較しながら分かりやすく解説します。

## ニューラルネットワークとは何か？

**ニューラルネットワークとは、人間の脳の神経細胞（ニューロン）の働きを模倣したコンピュータシステム** です。人間の脳には約860億個の神経細胞があり、それぞれが複雑につながり合って情報処理を行っています。

たとえば、あなたが熱いコーヒーカップを手で触った時を想像してみてください：

1. **感覚神経細胞** が熱さを感知する
2. **複数の神経細胞** がその情報を脳に伝達する
3. **脳の神経細胞** が「熱い！危険だ！」と判断する
4. **運動神経細胞** が手を引っ込める指令を出す

ニューラルネットワークも同じように、情報を受け取り、処理し、結果を出力する **人工の神経細胞** で構成されています。

### 人工ニューロンの基本構造

**人工ニューロン** は、人間の神経細胞を極めてシンプルに模倣したものです。次のような働きをします：

- **入力**：複数の情報（数値）を受け取る
- **重み付け**：それぞれの情報に重要度を割り当てる
- **統合**：全ての情報を合計する
- **判断**：閾値を超えたら「発火」（信号を出力）する

要するに、「複数の情報を総合的に判断して、イエスかノーかを決める小さな判断装置」なのです。

## 単純パーセプトロン：最初の人工ニューロン

**単純パーセプトロン** は、1957年にフランク・ローゼンブラットが開発した、最も基本的なニューラルネットワークです。「一つだけの人工ニューロン」とも言えます。

### 単純パーセプトロンの仕組み

単純パーセプトロンは以下のような構造を持っています：

```
入力1 × 重み1 ┐
入力2 × 重み2 ├─→ 合計 → 活性化関数 → 出力
入力3 × 重み3 ┘
```

**たとえば**、「雨が降るかどうか」を予測するパーセプトロンを考えてみましょう：

- **入力1**：湿度（0～100）
- **入力2**：気圧（990～1030）
- **入力3**：雲の量（0～10）

各入力に **重み** を掛けて足し合わせ、一定の **閾値** を超えたら「雨が降る」と判断します。

### 単純パーセプトロンの限界

しかし、単純パーセプトロンには重大な問題がありました。**線形分離可能な問題しか解けない** のです。

**たとえば**：
- **解ける問題**：「身長170cm以上かつ体重70kg以上なら大型」（AND論理）
- **解けない問題**：「男性または女性」（XOR論理）

要するに、「複雑な判断」はできないという限界があったのです。

## 多層パーセプトロン：複雑な問題への挑戦

**多層パーセプトロン** は、単純パーセプトロンの限界を克服するために開発された、 **複数層のニューロンを持つネットワーク** です。

### 多層パーセプトロンの基本構造

多層パーセプトロンは次の3つの層で構成されます：

#### 1. 入力層（Input Layer）
**入力層** は、外部からデータを受け取る層です。人間でいえば「目や耳」にあたります。

**たとえば**：
- 画像認識なら：各ピクセルの明るさ値
- 音声認識なら：各周波数の音の強さ
- 株価予測なら：過去の株価、出来高、経済指標

入力層のニューロン数は、扱うデータの種類によって決まります。

#### 2. 隠れ層（Hidden Layer）
**隠れ層** は、入力と出力の間にある層で、複雑な情報処理を行います。人間でいえば「脳の中の複雑な思考プロセス」にあたります。

隠れ層が **1つだけ** のネットワークを「浅いニューラルネットワーク」、 **2つ以上** のネットワークを「深いニューラルネットワーク（ディープラーニング）」と呼びます。

**隠れ層の役割**：
- 入力データから **特徴** を抽出する
- より **抽象的な概念** を学習する
- **非線形な関係** を捉える

#### 3. 出力層（Output Layer）
**出力層** は、最終的な結果を出力する層です。人間でいえば「判断結果を言葉や行動に表す」部分にあたります。

**たとえば**：
- 分類問題：「犬」「猫」「鳥」のどれか
- 回帰問題：具体的な数値（価格、温度など）
- 確率：「犬である確率85%」

### なぜ「隠れ層」と呼ぶのか？

隠れ層が「隠れ」と呼ばれる理由は、 **外部から直接見えない** からです。

**たとえば**、顔認識システムを考えてみましょう：
- **入力**：写真のピクセル値（目に見える）
- **出力**：「田中さんです」（目に見える）
- **隠れ層**：「目の形」「鼻の特徴」「輪郭」などを認識（内部処理で見えない）

要するに、隠れ層は「人間には見えない中間的な判断プロセス」を担当しているのです。

## 層の深さがもたらす表現力

### 浅いネットワーク vs 深いネットワーク

**浅いネットワーク（隠れ層1つ）** は：
- 比較的単純な関係を学習
- 計算が高速
- 過学習しにくい
- 表現力に限界

**深いネットワーク（隠れ層2つ以上）** は：
- 複雑で階層的な関係を学習
- 計算量が多い
- 過学習しやすい
- 高い表現力

**たとえば**、画像認識では：

```
入力層：ピクセル値
隠れ層1：エッジ（線）を検出
隠れ層2：形（円、四角）を検出
隠れ層3：部品（目、鼻、耳）を検出
隠れ層4：顔全体を認識
出力層：「人の顔」と判定
```

各層が前の層の結果を使って、より **抽象的で複雑な概念** を学習していくのです。

## ニューラルネットワークの学習プロセス

### 学習の仕組み

ニューラルネットワークは以下のプロセスで学習します：

1. **予測**：現在の重みで答えを出す
2. **誤差計算**：正解との差を計算する
3. **重み調整**：誤差を小さくするように重みを変更する
4. **繰り返し**：精度が十分になるまで1-3を繰り返す

**たとえば**、子供が算数を学ぶプロセスに似ています：
- 問題を解く（予測）
- 答え合わせをする（誤差計算）
- 間違いから学ぶ（重み調整）
- 練習問題を繰り返す（反復学習）

### 重みとバイアス

**重み（Weight）** は、各入力の **重要度** を表します。重要な情報ほど大きな重みを持ちます。

**バイアス（Bias）** は、ニューロンの **発火しやすさ** を調整します。

**たとえば**、レストランの評価システムなら：
- 味：重み 0.5（とても重要）
- 価格：重み 0.3（まあまあ重要）
- 立地：重み 0.2（それほど重要でない）
- バイアス：-2.0（厳しく評価する）

## 現代のディープラーニングへの発展

### ディープラーニングの定義

**ディープラーニング** は、 **隠れ層を多数持つニューラルネットワーク** を使った機械学習手法です。一般的に、隠れ層が2層以上あればディープラーニングと呼ばれます。

### なぜ「深い」ネットワークが重要なのか？

深いネットワークが重要な理由は、 **階層的な特徴抽出** ができるからです。

**たとえば**、自動運転車の物体認識では：

```
層1：ピクセル → エッジ検出
層2：エッジ → 基本図形検出
層3：基本図形 → 部品検出（タイヤ、窓）
層4：部品 → 物体認識（車、人、信号）
層5：物体 → 行動判断（停止、右折、加速）
```

各層が前の層で学習した **より単純な概念** を組み合わせて、 **より複雑な概念** を理解していくのです。

## まとめ

ニューラルネットワークは、単純パーセプトロンから多層パーセプトロン、そして現代のディープラーニングまで、段階的に発展してきました。要するに、「人工的な脳の神経回路」を作ることで、コンピュータに複雑な判断能力を与える技術なのです。

特に重要なポイントは：
- **入力層・隠れ層・出力層** の3層構造
- **隠れ層の深さ** が表現力を決める
- **重みとバイアス** の調整によって学習が進む

次回は、ディープラーニングを実際に動かすために必要なハードウェア技術について、同じように分かりやすく解説していきます。