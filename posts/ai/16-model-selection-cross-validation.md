---
title: "モデル選択と交差検証"
date: "2025-6-29"
tags: ["交差検証", "k分割交差検証", "過学習", "汎化性能", "AIC", "MSE", "RMSE", "MAE"]
section: "ai"
slug: "16-model-selection-cross-validation"
number: 16
category: "強化学習・評価編"
---

前回、モデルの性能を測る様々な指標について学びました。でも、「モデルの性能」って、どのデータで測るのが正しいのでしょうか？学習に使った同じデータで評価すると、成績が良く見えすぎてしまいます。この記事では、モデルの真の性能を正しく評価し、最適なモデルを選ぶための方法について解説します。

## なぜ適切な評価が難しいのか？

**機械学習の評価で最も重要なのは、「新しいデータに対してどれくらいうまく予測できるか」** を知ることです。これは、学校のテストに例えると分かりやすいでしょう。

**たとえば**：

- **教科書の問題**：何度も見た問題なので、暗記で解ける
- **テストの問題**：初めて見る問題でも解けるかが本当の実力

機械学習でも同じです：

- **学習データ**：モデルが学習に使ったデータ（教科書の問題と同じ）
- **テストデータ**：モデルが初めて見るデータ（テストの問題と同じ）

学習データでの性能が良くても、テストデータでの性能が悪ければ、そのモデルは実用的ではありません。

### 過学習の問題

**過学習（Overfitting）とは、学習データに特化しすぎて、新しいデータに対する性能が悪くなってしまう現象** です。

**たとえば**：

- **テスト対策の例**：過去問ばかり丸暗記して、似たような問題は解けるが、少し変わった問題には対応できない
- **料理の例**：一つのレシピは完璧に覚えているが、材料が少し変わると全く作れない

**過学習の特徴**：

1. **学習データ**での性能は非常に良い
2. **新しいデータ**での性能は悪い
3. **モデルが複雑すぎる**場合に起こりやすい

要するに、過学習したモデルは「融通が利かない」モデルなのです。

## 汎化性能とは

**汎化性能（Generalization Performance）とは、新しいデータに対してどれくらいうまく予測できるかを表す性能** です。これがモデルの真の価値を決めます。

### 汎化性能が重要な理由

実際のビジネスや研究では、モデルは常に「初めて見るデータ」を予測する必要があります。

**たとえば**：

- **株価予測**：過去のデータで学習して、明日の株価を予測する
- **医療診断**：過去の症例で学習して、新しい患者を診断する
- **商品レコメンド**：過去の購買履歴で学習して、新しい顧客に商品を推薦する

これらすべてで、「学習時には見たことのないデータ」に対して予測を行います。

### 汎化性能を高める方法

1. **適切なモデルの複雑さ**：複雑すぎず、単純すぎないモデルを選ぶ
2. **十分な学習データ**：多様なデータで学習させる
3. **正則化**：過学習を防ぐ技術を使う
4. **適切な特徴選択**：予測に本当に重要な特徴だけを使う

要するに、汎化性能を高めることが、実用的なモデルを作るための鍵なのです。

## 交差検証（Cross-Validation）

**交差検証とは、限られたデータを有効活用して、モデルの汎化性能を正確に評価する手法** です。

### 基本的な考え方

通常の評価方法では、データを2つに分けます：

- **学習データ**：モデルの学習に使用（例：全体の80%）
- **テストデータ**：性能評価に使用（例：全体の20%）

しかし、この方法には問題があります：

1. **データの無駄**：テストデータは学習に使えない
2. **評価の不安定性**：データの分け方によって結果が変わる
3. **データ不足**：小さなデータセットでは十分な学習ができない

交差検証は、これらの問題を解決します。

## k分割交差検証

**k分割交差検証（k-fold Cross-Validation）** は、最も一般的な交差検証の方法です。

### 基本的な手順

1. **データをk個に分割**（例：k=5なら5つのグループに分ける）
2. **1つをテスト用、残りを学習用**として使用
3. **k回繰り返し**、毎回異なるグループをテスト用にする
4. **k回の結果の平均**を最終的な性能とする

**たとえば（5分割交差検証）**：

```
データ全体: [A][B][C][D][E]

1回目: 学習[B][C][D][E] → テスト[A] → 性能85%
2回目: 学習[A][C][D][E] → テスト[B] → 性能88%
3回目: 学習[A][B][D][E] → テスト[C] → 性能82%
4回目: 学習[A][B][C][E] → テスト[D] → 性能87%
5回目: 学習[A][B][C][D] → テスト[E] → 性能84%

最終性能: (85 + 88 + 82 + 87 + 84) / 5 = 85.2%
```

### k分割交差検証の利点

- **データの有効活用**：すべてのデータが学習と評価の両方に使われる
- **安定した評価**：複数回の評価の平均なので、結果が安定する
- **汎化性能の正確な推定**：新しいデータに対する性能をより正確に予測できる

### kの選び方

**一般的な選択**：

- **k=5**：計算時間と精度のバランスが良い
- **k=10**：より精度の高い評価（計算時間は長くなる）
- **k=データ数**：Leave-One-Out交差検証（最も精度が高いが計算時間が長い）

**選択の基準**：

- **データが多い**：k=5で十分
- **データが少ない**：k=10やLeave-One-Out
- **計算時間を短縮したい**：k=3

要するに、データの量と計算資源に応じて適切なkを選ぶことが重要です。

## 回帰問題の評価指標

分類問題では前回解説した指標を使いますが、回帰問題（数値を予測する問題）では異なる指標を使います。

### MSE（平均二乗誤差）

**MSE（Mean Squared Error）とは、予測値と実際の値の差の二乗を平均した値** です。

```
MSE = Σ(予測値 - 実際の値)² / データ数
```

**たとえば**：

```
実際の値: [100, 200, 150, 180, 120]
予測値:   [95,  210, 145, 175, 125]
差:       [5,   -10, 5,   5,   -5]
二乗:     [25,  100, 25,  25,  25]
MSE = (25 + 100 + 25 + 25 + 25) / 5 = 40
```

**MSEの特徴**：

- **大きな誤差を重視**：二乗するので、大きな間違いが強く反映される
- **単位が元データの二乗**：解釈が少し難しい
- **数学的に扱いやすい**：最適化アルゴリズムで良く使われる

### RMSE（平均二乗誤差平方根）

**RMSE（Root Mean Squared Error）とは、MSEの平方根を取った値** です。

```
RMSE = √MSE
```

上の例では：
```
RMSE = √40 = 6.32
```

**RMSEの特徴**：

- **元データと同じ単位**：解釈しやすい
- **大きな誤差を重視**：MSEと同様の性質
- **一般的によく使われる**：回帰問題で最も人気の指標

### MAE（平均絶対誤差）

**MAE（Mean Absolute Error）とは、予測値と実際の値の差の絶対値を平均した値** です。

```
MAE = Σ|予測値 - 実際の値| / データ数
```

上の例では：
```
絶対値: [5, 10, 5, 5, 5]
MAE = (5 + 10 + 5 + 5 + 5) / 5 = 6
```

**MAEの特徴**：

- **直感的に分かりやすい**：「平均してどれくらい間違えるか」を表す
- **外れ値に頑健**：大きな誤差の影響を受けにくい
- **元データと同じ単位**：解釈しやすい

### 指標の使い分け

**RMSE vs MAE**：

- **RMSE**：大きな誤差を避けたい場合（例：安全性が重要な予測）
- **MAE**：外れ値の影響を減らしたい場合（例：ノイズの多いデータ）

**たとえば**：

- **株価予測**：大きな損失を避けたいのでRMSE
- **売上予測**：平均的な誤差を知りたいのでMAE

## AIC（赤池情報量規準）

**AIC（Akaike Information Criterion）とは、モデルの良さとシンプルさを両方考慮してモデルを選択する指標** です。

### AICの基本的な考え方

AICは以下の2つを同時に考慮します：

1. **フィット（適合度）**：データにどれくらい良く当てはまるか
2. **複雑さ（パラメータ数）**：モデルがどれくらいシンプルか

```
AIC = -2 × 対数尤度 + 2 × パラメータ数
```

**AICの特徴**：

- **値が小さいほど良い**：フィットが良く、かつシンプルなモデルが選ばれる
- **過学習を防ぐ**：複雑すぎるモデルにはペナルティが課される
- **モデル比較に便利**：異なるモデルを客観的に比較できる

### AICを使ったモデル選択

**たとえば**：

```
モデルA: AIC = 150 （シンプルだが精度が低い）
モデルB: AIC = 120 （適度な複雑さで良い精度）
モデルC: AIC = 140 （複雑だが精度はそれほど高くない）
```

この場合、AICが最も小さいモデルBを選択します。

要するに、AICは「良い性能とシンプルさのバランス」を数値化した指標なのです。

## モデル選択の実践的アプローチ

### 1. データの分割

```
全データ (100%)
├── 学習データ (60%) - モデルの学習に使用
├── 検証データ (20%) - モデル選択・ハイパーパラメータ調整に使用
└── テストデータ (20%) - 最終的な性能評価に使用
```

### 2. モデル選択の手順

1. **学習データ**で複数のモデルを学習
2. **交差検証**で各モデルの汎化性能を推定
3. **最も良いモデル**を選択
4. **テストデータ**で最終的な性能を評価

### 3. 注意点

- **テストデータは最後まで使わない**：モデル選択には使用しない
- **交差検証は学習データ内で実施**：テストデータは含めない
- **複数の指標を併用**：一つの指標だけでなく、総合的に判断

要するに、適切なモデル選択には、正しい評価手順を守ることが不可欠です。

## まとめ

モデル選択と交差検証は、実用的な機械学習システムを構築するための基本的な技術です。過学習を避け、汎化性能の高いモデルを選ぶためには、適切な評価方法と指標の理解が不可欠です。

要するに、「学習データで良い性能」ではなく、「新しいデータで良い性能」を目指すことが、成功する機械学習プロジェクトの鍵なのです。

次回は、これまで学んだ基礎的な機械学習の知識を活かして、より高度なニューラルネットワークの基本構造について解説していきます。